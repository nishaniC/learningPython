import math


class Point:
    def __init__(self, x=0.0, y=0.0):
        self.__x=x
        self.__y=y

    def getx(self):
        return self.__x

    def gety(self):
        return self.__y

    def distance_from_xy(self, x, y):
        if self.__x>x:
            x=self.__x-x
        else:
            x=x-self.__x
        if self.__y>y:
            y=self.__y-y
        else:
            y=y-self.__y
            
        return math.hypot(x,y)
        # Square the first side, a.
# Add the square of the second side, b to it.
# Subtract the square of the third side, c from the sum.
# Divide the difference by the length of second side.
# Divide the quotient by the length of first side.


    def distance_from_point(self, point):
        if self.__x>point.getx():
            x=self.__x-point.getx()
        else:
            x=point.getx()-self.__x
        if self.__y>point.gety():
            y=self.__y-point.gety()
        else:
            y=point.gety()-self.__y
            
        return math.hypot(x,y)

point1 = Point(0, 0)
point2 = Point(1, 1)
print(point1.distance_from_point(point2))
print(point2.distance_from_xy(2, 0))
